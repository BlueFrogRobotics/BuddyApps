<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Vision</name>
    </assembly>
    <members>
        <member name="T:BuddyFeature.Vision.AVisionAlgorithm">
            <summary>
            Base class for computer vision algorithms.
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.AVisionAlgorithm.handleOutputTexture">
            <summary>
            If true, the AVisionAlgorithm process will convert automaticaly
            the OutputFrame to a Texture2D after ProcessAlgorithm.
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.AVisionAlgorithm.mOutputFrameMat">
            <summary>
            The image that will be converted to frame texture for display.
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.AVisionAlgorithm.mHeight">
            <summary>
            Height of the frame in pixels.
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.AVisionAlgorithm.mWidth">
            <summary>
            Width of the frame in pixels.
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.AVisionAlgorithm.mOutputFrameMatType">
            <summary>
            CvType of the frame (OpenCVUnity format).
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.AVisionAlgorithm.mTimerToProcess">
            <summary>
            Time needed before call processing algorithm.
            Zero if not initialized.
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.AVisionAlgorithm.mCurrentFrameID">
            <summary>
            ID of the frame.
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.AVisionAlgorithm.mInputFrameMat">
            <summary>
            The image that will be processed.
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.AVisionAlgorithm.mOutputFrameTexture">
            <summary>
            The image for display.
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.AVisionAlgorithm.mCountdown">
            <summary>
            Countdown before call processing algorithm.
            Update a each frame.
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.AVisionAlgorithm.mWebcam">
            <summary>
            Real or Simulate camera of the robot.
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.AVisionAlgorithm.FrameMat">
            <summary>
            Gets the frame. Must be updated by the custom algorithm.
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.AVisionAlgorithm.FrameTexture2D">
            <summary>
            Gets the frame. Will be automaticaly created from FrameMat.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.AVisionAlgorithm.Start">
            <summary>
            Called once at the beginning.
            Init with basic values.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.AVisionAlgorithm.Update">
            <summary>
            Called at each frame.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.AVisionAlgorithm.RetrieveFrame">
            <summary>
            Ensures that mFrameMat and mFrameTexture will always be at the same size.
            </summary>
            <remarks>
            When called at each frame, the UpdateFrame() allows to get the current 
            frame from the (simulate or real) RGB camera of the robot.
            </remarks>
            <returns>The current frame in OpenCVUnity format</returns>
        </member>
        <member name="M:BuddyFeature.Vision.AVisionAlgorithm.Init">
            <summary>
            Called one time after the start method.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.AVisionAlgorithm.ProcessFrameImpl(OpenCVUnity.Mat,UnityEngine.Texture2D)">
            <summary>
            Called at each valuable frame.
            Write your computer vision algorithm inside this method.
            </summary>
            <param name="iInputFrameMat">The current frame (in CV_8UC3) to process</param>
            <param name="iInputFrameTexture">The current frame (in 2D texture format) to process</param>
        </member>
        <member name="T:BuddyFeature.Vision.DetectionType">
            <summary>
            Kind of detection request for Google Cloud Vision API
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.DetectionType.TYPE_UNSPECIFIED">
            <summary>
            Misc
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.DetectionType.FACE_DETECTION">
            <summary>
            Face information
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.DetectionType.LANDMARK_DETECTION">
            <summary>
            Landmark (Eiffel tower, Golden Bridge, left eye, right hand...)
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.DetectionType.LOGO_DETECTION">
            <summary>
            Logo detection (Coca cola ...)
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.DetectionType.LABEL_DETECTION">
            <summary>
            Labelization (desk, floor, robot, window, hand ...)
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.DetectionType.TEXT_DETECTION">
            <summary>
            Optical Character Recognition
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.DetectionType.SAFE_SEARCH_DETECTION">
            <summary>
            Does this content is safe for children ? (blood, violence, explicit scene ...)
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.DetectionType.IMAGE_PROPERTIES">
            <summary>
            Image properties (main color, )
            </summary>
        </member>
        <member name="T:BuddyFeature.Vision.LandmarkType">
            <summary>
            Kind of landmark
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.UNKNOWN_LANDMARK">
            <summary>
            Unknown landmark
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.LEFT_EYE">
            <summary>
            Left eye
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.RIGHT_EYE">
            <summary>
            Right eye
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.LEFT_OF_LEFT_EYEBROW">
            <summary>
            Left of left eyebrow
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.RIGHT_OF_LEFT_EYEBROW">
            <summary>
            Right of left eyebrow
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.LEFT_OF_RIGHT_EYEBROW">
            <summary>
            Left of right eyebrow
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.RIGHT_OF_RIGHT_EYEBROW">
            <summary>
            Right of left eyebrow
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.MIDPOINT_BETWEEN_EYES">
            <summary>
            Space between eyes
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.NOSE_TIP">
            <summary>
            Nose tip
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.UPPER_LIP">
            <summary>
            Upper lip
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.LOWER_LIP">
            <summary>
            Lower lip
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.MOUTH_LEFT">
            <summary>
            Mouse left side
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.MOUTH_RIGHT">
            <summary>
            Mouse right side
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.MOUTH_CENTER">
            <summary>
            Center of the mouse
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.NOSE_BOTTOM_RIGHT">
            <summary>
            Bottom right side of the nose
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.NOSE_BOTTOM_LEFT">
            <summary>
            Bottom left side of the nose
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.NOSE_BOTTOM_CENTER">
            <summary>
            Bottom center side of the nose
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.LEFT_EYE_TOP_BOUNDARY">
            <summary>
            Left eye top boundary
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.LEFT_EYE_RIGHT_CORNER">
            <summary>
            Left eye right corner
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.LEFT_EYE_BOTTOM_BOUNDARY">
            <summary>
            Left eye bottom boundary
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.LEFT_EYE_LEFT_CORNER">
            <summary>
            Left eye left corner
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.RIGHT_EYE_TOP_BOUNDARY">
            <summary>
            Right eye top boundary
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.RIGHT_EYE_RIGHT_CORNER">
            <summary>
            RIght eye right corner
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.RIGHT_EYE_BOTTOM_BOUNDARY">
            <summary>
            Right eye bottom boundary
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.RIGHT_EYE_LEFT_CORNER">
            <summary>
            Right eye left corner 
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.LEFT_EYEBROW_UPPER_MIDPOINT">
            <summary>
            Left eyebrown upper midpoint
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.RIGHT_EYEBROW_UPPER_MIDPOINT">
            <summary>
            Right eyebrown upper midpoint
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.LEFT_EAR_TRAGION">
            <summary>
            Left ear tragion
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.RIGHT_EAR_TRAGION">
            <summary>
            Right eear tragion
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.LEFT_EYE_PUPIL">
            <summary>
            Left eye pupil
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.RIGHT_EYE_PUPIL">
            <summary>
            Right eye pupil
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.FOREHEAD_GLABELLA">
            <summary>
            Glabella
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.CHIN_GNATHION">
            <summary>
            Chin gnathion
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.CHIN_LEFT_GONION">
            <summary>
            Chin left gonion
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.LandmarkType.CHIN_RIGHT_GONION">
            <summary>
            Chin right gonion
            </summary>
        </member>
        <member name="T:BuddyFeature.Vision.Likelihood">
            <summary>
            Rate likelihood
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.Likelihood.UNKNOWN">
            <summary>
            Unknown
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.Likelihood.VERY_UNLIKELY">
            <summary>
            Very low rate
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.Likelihood.UNLIKELY">
            <summary>
            Low rate
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.Likelihood.POSSIBLE">
            <summary>
            Medium rate 
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.Likelihood.LIKELY">
            <summary>
            Correct rate
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.Likelihood.VERY_LIKELY">
            <summary>
            Very credible
            </summary>
        </member>
        <member name="T:BuddyFeature.Vision.GoogleCloudVision">
            <summary>
            To use this feature, you must assign GOOGLE_API_KEY with your own Google vision API key.
            Available at https://console.cloud.google.com/projectselector/apis/credentials
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.GoogleCloudVision.Detect(OpenCVUnity.Mat,BuddyFeature.Vision.DetectionType,BuddyFeature.Vision.Impl.AnnotateImageResponses,System.Int32)">
            <summary>
            Detect the wanted feature in the input image
            </summary>
            <param name="iImage">The image to retrieve info</param>
            <param name="iFeatureType">The kind of feature</param>
            <param name="ioResponses">The output Annotate response</param>
            <param name="iMaxResult">Max wish results</param>
            <returns>IEnumerator for yield return</returns>
        </member>
        <member name="M:BuddyFeature.Vision.GoogleCloudVision.Detect(UnityEngine.Texture2D,BuddyFeature.Vision.DetectionType,BuddyFeature.Vision.Impl.AnnotateImageResponses,System.Int32)">
            <summary>
            Detect the wanted feature in the input image
            </summary>
            <param name="iImage">The image to retrieve info</param>
            <param name="iFeatureType">The kind of feature</param>
            <param name="ioResponses">The output Annotate response</param>
            <param name="iMaxResult">Max wish results</param>
            <returns>IEnumerator for yield return</returns>
        </member>
        <member name="M:BuddyFeature.Vision.GoogleCloudVision.Detect(System.Byte[],BuddyFeature.Vision.DetectionType,BuddyFeature.Vision.Impl.AnnotateImageResponses,System.Int32)">
            <summary>
            Detect the wanted feature in the input image
            </summary>
            <param name="iImage">The image to retrieve info</param>
            <param name="iFeatureType">The kind of feature</param>
            <param name="ioResponses">The output Annotate response</param>
            <param name="iMaxResult">Max wish results</param>
            <returns>IEnumerator for yield return</returns>
        </member>
        <member name="M:BuddyFeature.Vision.GoogleCloudVision.DetectImpl(OpenCVUnity.Mat,BuddyFeature.Vision.DetectionType,BuddyFeature.Vision.Impl.AnnotateImageResponses,System.Int32)">
            <summary>
            Detect the wanted feature in the input image
            </summary>
            <param name="iImage">The image to retrieve info</param>
            <param name="iFeatureType">The kind of feature</param>
            <param name="ioResponses">The output Annotate response</param>
            <param name="iMaxResult">Max wish results</param>
            <returns>IEnumerator for yield return</returns>
        </member>
        <member name="M:BuddyFeature.Vision.GoogleCloudVision.DetectImpl(UnityEngine.Texture2D,BuddyFeature.Vision.DetectionType,BuddyFeature.Vision.Impl.AnnotateImageResponses,System.Int32)">
            <summary>
            Detect the wanted feature in the input image
            </summary>
            <param name="iImage">The image to retrieve info</param>
            <param name="iFeatureType">The kind of feature</param>
            <param name="ioResponses">The output Annotate response</param>
            <param name="iMaxResult">Max wish results</param>
            <returns>IEnumerator for yield return</returns>
        </member>
        <member name="M:BuddyFeature.Vision.GoogleCloudVision.DetectImpl(System.Byte[],BuddyFeature.Vision.DetectionType,BuddyFeature.Vision.Impl.AnnotateImageResponses,System.Int32)">
            <summary>
            Detect the wanted feature in the input image
            </summary>
            <param name="iImage">The image to retrieve info</param>
            <param name="iFeatureType">The kind of feature</param>
            <param name="ioResponses">The output Annotate response</param>
            <param name="iMaxResult">Max wish results</param>
            <returns>IEnumerator for yield return</returns>
        </member>
        <member name="T:BuddyFeature.Vision.Impl.DQrCode">
            <summary>
            Define Class of a QRCode
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.Impl.DQrCode.#ctor(System.String,BuddyTools.Tuple{OpenCVUnity.Point,OpenCVUnity.Point,OpenCVUnity.Point})">
            <summary>
            Constucteur
            </summary>
            <param name="iName">Name is the string value of Qrcode</param>
            <param name="iCoordinates">Three point of coordiante tuple</param>
        </member>
        <member name="M:BuddyFeature.Vision.Impl.DQrCode.#ctor(BuddyFeature.Vision.Impl.DQrCode)">
            <summary>
            Constucteur QrCode from an other Qrcode
            </summary>
            <param name="iQrCode">QRCode to translate</param>
        </member>
        <member name="P:BuddyFeature.Vision.Impl.DQrCode.Name">
            <summary>
            Get the QrCode name
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.Impl.DQrCode.Coordinates">
            <summary>
            Accessore for the coordinates of QrCode
            </summary>
        </member>
        <member name="T:BuddyFeature.Vision.OpticalCharacterRecognizer">
            <summary>
            WORK IN PROGRESS : OCR works only on Windows editor and Windows build.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.OpticalCharacterRecognizer.ProcessFrameImpl(OpenCVUnity.Mat,UnityEngine.Texture2D)">
            <summary>
            Apply an optical character recognition over the preprocessed input frame.
            </summary>
            <param name="iInputFrameMat">Mat format of the frame</param>
            <param name="iInputFrameTexture">Texture2D format of the frame</param>
        </member>
        <member name="M:BuddyFeature.Vision.OpticalCharacterRecognizer.Apply">
            <summary>
            Apply all changes over the OCR
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.OpticalCharacterRecognizer.ReplaceUnWantedCharacters(System.String)">
            <summary>
            Replace bad characters inside the input string
            </summary>
            <param name="iString">The string to correct</param>
            <returns>The corrected string</returns>
        </member>
        <member name="M:BuddyFeature.Vision.OpticalCharacterRecognizer.IsCorrectWord(System.String)">
            <summary>
            Check if the word is correct after the recognition
            </summary>
            <param name="iString">The word to check</param>
            <returns>Correctness of the word</returns>
        </member>
        <member name="T:BuddyFeature.Vision.ARecognizer">
            <summary>
            Abstract class for recognition behaviour model
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.ARecognizer.mIsTrained">
            <summary>
            Is the model is trained ?
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.ARecognizer.IsTrained">
            <summary>
            Is the model is trained ?
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.ARecognizer.Predict(System.Collections.Generic.List{OpenCVUnity.Mat})">
            <summary>
            Predict the class of the input data
            </summary>
            <param name="iImages">Input data</param>
            <returns>Class of each input data</returns>
        </member>
        <member name="M:BuddyFeature.Vision.ARecognizer.Predict(OpenCVUnity.Mat[])">
            <summary>
            Predict the class of the input data
            </summary>
            <param name="iImages">Input data</param>
            <returns>Class of each input data</returns>
        </member>
        <member name="M:BuddyFeature.Vision.ARecognizer.Load(System.String)">
            <summary>
            Asynchronous model loading
            </summary>
            <param name="iPathToModel">Path to the xml model</param>
        </member>
        <member name="M:BuddyFeature.Vision.ARecognizer.Predict(OpenCVUnity.Mat)">
            <summary>
            Predict the class of the input frame
            </summary>
            <param name="iImage">Input data</param>
            <returns>Class of the data</returns>
        </member>
        <member name="M:BuddyFeature.Vision.ARecognizer.Train(System.Collections.Generic.List{OpenCVUnity.Mat},System.Collections.Generic.List{System.Int32})">
            <summary>
            Train the classifier
            </summary>
            <param name="iTrainingSet">Set of data</param>
            <param name="iLabelSet">Label corresponding to each data</param>
        </member>
        <member name="M:BuddyFeature.Vision.ARecognizer.Train(System.String)">
            <summary>
            Train data with LBPH algorithm from the input directory of data. 
            Directory must contains sub directories with face images.
            </summary>
            <param name="iPathToDirectory">Path to the root directory containing profil directories</param>
        </member>
        <member name="M:BuddyFeature.Vision.ARecognizer.LoadModel(System.String)">
            <summary>
            Load the existing model in a xml file
            </summary>
            <param name="iPathToModel">Path to file model</param>
        </member>
        <member name="T:BuddyFeature.Vision.FaceRecoMode">
            <summary>
            Recognition mode
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.FaceRecoMode.RECOGNITION">
            <summary>
            Algorithm will recognize input faces using the FaceShiftTracker
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.FaceRecoMode.TRACKING">
            <summary>
            Track face and add continuous face as a same profil
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.FaceRecoMode.NONE">
            <summary>
            Do nothing
            </summary>
        </member>
        <member name="T:BuddyFeature.Vision.FaceRecognizer">
            <summary>
            Use the Local Binary Patterns Histograms for face recognition
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.FaceRecognizer.mLBPHFace">
            <summary>
            Local Binary Patterns Histograms OpenCV Contrib for face recognition
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.FaceRecognizer.mMatcher">
            <summary>
            Profil matcher in order to merge profils
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.FaceRecognizer.RecognizedProfils">
            <summary>
            Instant recognized profils
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.FaceRecognizer.StabilizedRecognizedProfils">
            <summary>
            Recognized profils after stabilization
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.FaceRecognizer.UnRecognizedFaces">
            <summary>
            Tracked face but unrecognized 
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.FaceRecognizer.FaceRecoMode">
            <summary>
            Current mode
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.FaceRecognizer.Init">
            <summary>
            Initialization
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.FaceRecognizer.ProcessFrameImpl(OpenCVUnity.Mat,UnityEngine.Texture2D)">
            <summary>
            Apply the specific algorithm according to the input key
            </summary>
            <param name="iInputFrameMat">Mat format of the frame</param>
            <param name="iInputFrameTexture">Texture2D format of the frame</param>
        </member>
        <member name="M:BuddyFeature.Vision.FaceRecognizer.Predict(OpenCVUnity.Mat)">
            <summary>
            Predict the class of the input image.
            </summary>
            <param name="iImage">The preprocessed image</param>
            <returns>The index of the class according to the classification</returns>
        </member>
        <member name="M:BuddyFeature.Vision.FaceRecognizer.Train(System.Collections.Generic.List{OpenCVUnity.Mat},System.Collections.Generic.List{System.Int32})">
            <summary>
            Train the LBPH according to input set and corresponding labels
            </summary>
            <param name="iTrainingSet">The set of preprocessed images</param>
            <param name="iLabelSet">Corresponding labels of each image</param>
        </member>
        <member name="M:BuddyFeature.Vision.FaceRecognizer.Train(System.String)">
            <summary>
            Train data with LBPH algorithm from the input directory of data. 
            Directory must contains sub directories with face images.
            </summary>
            <param name="iPathToDirectory">Path to the root directory containing profil directories</param>
        </member>
        <member name="M:BuddyFeature.Vision.FaceRecognizer.LoadModel(System.String)">
            <summary>
            Load the existing model in a xml file
            </summary>
            <param name="iPathToModel">Path to file model</param>
        </member>
        <member name="M:BuddyFeature.Vision.FaceRecognizer.RegisterProfils(OpenCVUnity.Mat)">
            <summary>
            Create a profil for each new tracked face.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.FaceRecognizer.RecognizeFaces(OpenCVUnity.Mat)">
            <summary>
            Get recognized profils from current tracked faces.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.FaceRecognizer.StabilizeRecognition">
            <summary>
            Stabilize the recognition by processing a simple mean of each recognition on each tracked profil
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.FaceRecognizer.DisplayRecognition(System.Collections.Generic.List{BuddyOS.UserProfil},System.Collections.Generic.List{BuddyOS.TrackedObject})">
            <summary>
            Display classification result on output frame.
            </summary>
            <param name="iRecognizedProfils">Recognized profils</param>
            <param name="iUnRecognizedProfils">Unrecognized profils (as tracked object only)</param>
        </member>
        <member name="M:BuddyFeature.Vision.FaceRecognizer.LearnProfilsWithClustering">
            <summary>
            Process a clustering on a non labeled set and train the classifier
            Clustering based on a succession of Expectation Maximization algorithm
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.FaceRecognizer.LearnProfils">
            <summary>
            Learn Data base profils.
            </summary>
        </member>
        <member name="T:BuddyFeature.Vision.GenderRecognizer">
            <summary>
            Gender recognition based on the Local Binary Pattern Histogram learning.
            This component use a face shift tracker for localization and tracking.
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.GenderRecognizer.RecognizedGender">
            <summary>
            Current recognized tracked gender
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.GenderRecognizer.Init">
            <summary>
            Initialization
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.GenderRecognizer.ProcessFrameImpl(OpenCVUnity.Mat,UnityEngine.Texture2D)">
            <summary>
            Predict if the preprocessed input frame contains a face of a male or female (not 100% accurate...)
            </summary>
            <param name="iInputFrameMat">Mat format of the frame</param>
            <param name="iInputFrameTexture">Texture2D format of the frame</param>
        </member>
        <member name="M:BuddyFeature.Vision.GenderRecognizer.Predict(OpenCVUnity.Mat)">
            <summary>
            Predict the class of the input preprocessed face contained in the image
            </summary>
            <param name="iImage">Frame with face</param>
            <returns>The class (female or male) of the face</returns>
        </member>
        <member name="M:BuddyFeature.Vision.GenderRecognizer.Train(System.Collections.Generic.List{OpenCVUnity.Mat},System.Collections.Generic.List{System.Int32})">
            <summary>
            Train the classifier
            </summary>
            <param name="iTrainingSet">Set of images containing face of male or female</param>
            <param name="iLabelSet">Corresponding labels</param>
        </member>
        <member name="M:BuddyFeature.Vision.GenderRecognizer.Train(System.String)">
            <summary>
            Train data with LBPH algorithm from the input directory of data. 
            Directory must contains sub directories with face images.
            </summary>
            <param name="iPathToDirectory">Path to the root directory containing profil directories</param>
        </member>
        <member name="M:BuddyFeature.Vision.GenderRecognizer.LoadModel(System.String)">
            <summary>
            Load the existing model in a xml file
            </summary>
            <param name="iPathToModel">Path to file model</param>
        </member>
        <member name="T:BuddyFeature.Vision.FaceCascadeTracker">
            <summary>
            Face tracker using continuous Haar cascade feature and local CascadeClassifier algorithm
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.FaceCascadeTracker.TrackedObjects">
            <summary>
            Current tracked objects on the current frame
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.FaceCascadeTracker.Init">
            <summary>
            Called one time at the start.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.FaceCascadeTracker.ProcessFrameImpl(OpenCVUnity.Mat,UnityEngine.Texture2D)">
            <summary>
            Called at each valuable frame.
            </summary>
        </member>
        <member name="T:BuddyFeature.Vision.AShiftTracker">
            <summary>
            Tracking with continuous adaptative mean shift.
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.AShiftTracker.TrackedObjects">
            <summary>
            Tracked objects
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.AShiftTracker.NbTrackedObjects">
            <summary>
            Number of currently detected objects.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.AShiftTracker.Init">
            <summary>
            Called one time at the start.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.AShiftTracker.ProcessFrameImpl(OpenCVUnity.Mat,UnityEngine.Texture2D)">
            <summary>
            Called at each valuable frame.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.AShiftTracker.ResetTracking">
            <summary>
            Reset all current tracking
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.AShiftTracker.DetectObjectsImpl(OpenCVUnity.Mat,UnityEngine.Texture2D)">
            <summary>
            Retrieve tracked object in the frame
            </summary>
            <param name="iInputFrameMat">The current frame (OpenCVUnity)</param>
            <param name="iInputFrameTexture">The current frame (Unity3D)</param>
            <returns>Retrieve tracked objects</returns>
        </member>
        <member name="T:BuddyFeature.Vision.FaceShiftTracker">
            <summary>
            Simple face detection algorithm.
            </summary>
        </member>
        <member name="F:BuddyFeature.Vision.FaceShiftTracker.mFaceClassifier">
            <summary>
            Classifier trained on haar features.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.FaceShiftTracker.Init">
            <summary>
            Called one time at the start.
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.FaceShiftTracker.DetectObjectsImpl(OpenCVUnity.Mat,UnityEngine.Texture2D)">
            <summary>
            Retrieve tracked object in the frame
            </summary>
            <param name="iInputFrameMat">The current frame (OpenCVUnity)</param>
            <param name="iInputFrameTexture">The current frame (Unity3D)</param>
            <returns>Retrieve tracked objects</returns>
        </member>
        <member name="T:BuddyFeature.Vision.QrCodeReader">
            <summary>
            Class use to Decode a QRCode with a list of pre-set QRCode
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.QrCodeReader.QrcodesDetectedList">
            <summary>
            Get the list of all Qrcodes detected
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.QrCodeReader.LastQrCodeDetected">
            <summary>
            Get the last QrCode detected
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.QrCodeReader.NumberQrCodeDetected">
            <summary>
            Get number of QrCode detected at this moment
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.QrCodeReader.NameLastQrCode">
            <summary>
            Get the name of the last Qrcode detected
            </summary>
        </member>
        <member name="P:BuddyFeature.Vision.QrCodeReader.ThreadSleepTime">
            <summary>
            Get/Set sleep time for thread for decoding
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.QrCodeReader.Init">
            <summary>
            Init members and start a thread for decoding
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.QrCodeReader.OnEnable">
            <summary>
            Init members and start a thread for decoding
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.QrCodeReader.OnDisable">
            <summary>
            Abort thread for decoding
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.QrCodeReader.OnDestroy">
            <summary>
            Abort thread for decoding if is not already aborted
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.QrCodeReader.OnApplicationQuit">
            <summary>
            Stop the thread for decoding
            </summary>
            <remarks>
            It's better to stop the thread by itself rather than abort it.
            </remarks>
        </member>
        <member name="M:BuddyFeature.Vision.QrCodeReader.ProcessFrameImpl(OpenCVUnity.Mat,UnityEngine.Texture2D)">
            <summary>
            Compute called every frame.
            </summary>
            <remarks>
            Cannot be multithreaded.
            </remarks>
            <param name="iInputFrameMat">Get a matrix from cam and convert it in Array color32 for decoding</param>
        </member>
        <member name="M:BuddyFeature.Vision.QrCodeReader.DecodeQR">
            <summary>
            Is called in thread for detect QRcode
            </summary>
        </member>
        <member name="M:BuddyFeature.Vision.QrCodeReader.ConvertResultPointToPoint(ZXing.ResultPoint)">
            <summary>
            Convert a ResultPoint to a point
            </summary>
            <param name="iResultPoint">ResultPoint for conversion</param>
            <returns>Point</returns>
        </member>
        <member name="M:BuddyFeature.Vision.QrCodeReader.AddQrCodeInQrCodeList(System.String,System.Collections.Generic.List{OpenCVUnity.Point})">
            <summary>
            Add a new QrCode in a list of QrCode detected 
            </summary>
            <param name="iName">Name of QrCode</param>
            <param name="iCoordinates">Coordinates of QrCode</param>
            <returns>New QrCode</returns>
        </member>
    </members>
</doc>
